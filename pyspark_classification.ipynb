{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Classification in PySpark\n",
        "- This notebook covers developing a machine learning model in `PySpark` environment.\n",
        "- Dataset used for analysis is [\n",
        "SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) taken from UCI Machine Learning Repository. A binary classification model is developed on this dataset to identify if the given text message a `Spam` message or a `Ham` message.\n",
        "- Different data transformation and NLP techniques in PySpark environment are applied for Text cleaning and pre-processing.\n",
        "- Classification model developement and tuning is performed under PySpark framework."
      ],
      "metadata": {
        "id": "Jw-CJrzgSfUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installing Spark and JDK files to run a spark session on local computer"
      ],
      "metadata": {
        "id": "RsltP-EwUjAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPH8ApDlh-KM"
      },
      "outputs": [],
      "source": [
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get update\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "# !tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "# !pip install -q findspark"
      ],
      "metadata": {
        "id": "KA0z1l71iDkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "id": "1UJ-JbOpiE3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries to start a spark session\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "FZV7kmOgiG-e",
        "outputId": "e9825502-4e95-4801-fc24-8d468bf75ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ff007d19f50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://683f9a12427a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries necessary for data cleaning, pre-processin, ml model developement etc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from pyspark.sql.types import ArrayType, DataType, StringType\n",
        "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StopWordsRemover, Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator,  MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "7MZXS1yDiIc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data import and Target definition"
      ],
      "metadata": {
        "id": "2EvXgpkkWUmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing model development data as a spark dataframe\n",
        "\n",
        "df = spark.read.csv('/content/ClfData.csv', header=True, inferSchema=True)\n",
        "print(df.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubosCyAPipoU",
        "outputId": "28ab3100-3b33-445f-f22f-4821b9f653e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|Flag|                SMS |\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding an ID column to the dataset using pyspark functions\n",
        "\n",
        "df = df.select('*').withColumn('ID', f.monotonically_increasing_id())\n",
        "print('\\nTop 5 rows')\n",
        "print(df.show(5))\n",
        "print('\\nBottom 5 rows')\n",
        "print(df.orderBy(f.desc('ID')).show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA7hCPwQjFbw",
        "outputId": "d9019e7f-2e9f-462d-8165-0d6970b211da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 rows\n",
            "+----+--------------------+---+\n",
            "|Flag|                SMS | ID|\n",
            "+----+--------------------+---+\n",
            "| ham|Go until jurong p...|  0|\n",
            "| ham|Ok lar... Joking ...|  1|\n",
            "|spam|Free entry in 2 a...|  2|\n",
            "| ham|U dun say so earl...|  3|\n",
            "| ham|Nah I don't think...|  4|\n",
            "+----+--------------------+---+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "\n",
            "Bottom 5 rows\n",
            "+----+--------------------+----+\n",
            "|Flag|                SMS |  ID|\n",
            "+----+--------------------+----+\n",
            "| ham|Rofl. Its true to...|5573|\n",
            "| ham|The guy did some ...|5572|\n",
            "| ham|Pity, * was in mo...|5571|\n",
            "| ham|Will Ã¼ b going t...|5570|\n",
            "|spam|This is the 2nd t...|5569|\n",
            "+----+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data Shape : {} Rows - {} Columns'.format((df.count()), (len(df.columns))))\n",
        "print('Class Distribution')\n",
        "df.groupBy('Flag').count().orderBy('count').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tkVG9GumRbj",
        "outputId": "77498627-74e2-47f8-9fc7-78eedd9f9bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape : 5574 Rows - 3 Columns\n",
            "Class Distribution\n",
            "+----+-----+\n",
            "|Flag|count|\n",
            "+----+-----+\n",
            "|spam|  747|\n",
            "| ham| 4827|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iFFeayRnYZs",
        "outputId": "cd757b5b-1c67-4362-8342-fbeae54fa4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Flag', 'SMS ', 'ID']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming columns in a spark dataframe; the renaming commands are different from pandas commands\n",
        "\n",
        "df = df.withColumnRenamed('SMS ', 'SMS')\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4zej4x7nsvr",
        "outputId": "9bece86b-70d3-4985-93ad-a9b6ca553f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Flag', 'SMS', 'ID']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Target/Y column : Flag into a numeric Target/Y indicator using pyspark's StringIndexer\n",
        "# 0 = Ham, 1 = Spam message\n",
        "\n",
        "string_indexer = StringIndexer(inputCol='Flag', outputCol='Spam').fit(df)\n",
        "df = string_indexer.transform(df)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li-PIqVJjICE",
        "outputId": "367eee8b-ed8d-40b9-8fbc-31892f6637bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+---+----+\n",
            "|Flag|                 SMS| ID|Spam|\n",
            "+----+--------------------+---+----+\n",
            "| ham|Go until jurong p...|  0| 0.0|\n",
            "| ham|Ok lar... Joking ...|  1| 0.0|\n",
            "|spam|Free entry in 2 a...|  2| 1.0|\n",
            "| ham|U dun say so earl...|  3| 0.0|\n",
            "| ham|Nah I don't think...|  4| 0.0|\n",
            "+----+--------------------+---+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Pre-processing using NLP techniques"
      ],
      "metadata": {
        "id": "xZkMhRi7WvK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new dataframe to process and save text data\n",
        "\n",
        "df_processed = df"
      ],
      "metadata": {
        "id": "bG1lXUg2p690"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text data into lower case and saving the results in a new column : 'SMS_Processed'\n",
        "\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.lower(df_processed.SMS))\n",
        "df_processed.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8zjkgbYljbW",
        "outputId": "b786ae8c-3880-4b15-b92c-08f1b7c4f813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar... joking wif u oni...'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed=\"free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005. text fa to 87121 to receive entry question(std txt rate)t&c's apply 08452810075over18's\"),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say so early hor... u c already then say...'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed=\"nah i don't think he goes to usf, he lives around here though\")]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing all HTML tags from text data and checking the results for first 5 rows\n",
        "\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.regexp_replace(df_processed.SMS_Processed, r'<.*?>', ''))\n",
        "df_processed.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6O4Wu5ymvSQ",
        "outputId": "64649c33-e1a4-45fc-ccf0-fa452bda6a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar... joking wif u oni...'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed=\"free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005. text fa to 87121 to receive entry question(std txt rate)t&c's apply 08452810075over18's\"),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say so early hor... u c already then say...'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed=\"nah i don't think he goes to usf, he lives around here though\")]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing all pucntuations from text data and checking the results for first 5 rows\n",
        "\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.regexp_replace(df_processed.SMS_Processed, r'[^\\w\\s]', ''))\n",
        "df_processed.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntn-Id_o1za",
        "outputId": "3455c48c-8620-4437-a536-1c481232b4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say so early hor u c already then say'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed='nah i dont think he goes to usf he lives around here though')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing unicodes from text data and checking the results for first 5 rows\n",
        "\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.regexp_replace(df_processed.SMS_Processed, r'[^\\x00-\\x7F]+', ''))\n",
        "df_processed.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-B4K-HWo3Cl",
        "outputId": "877db70e-747b-4c0b-b4a0-80cfb6398aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s'),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say so early hor u c already then say'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed='nah i dont think he goes to usf he lives around here though')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing the text data and saving the result as lists in a new column : SMS_Token\n",
        "\n",
        "tokenizer = Tokenizer(inputCol='SMS_Processed', outputCol='SMS_Tokens')\n",
        "df_processed = tokenizer.transform(df_processed)\n",
        "df_processed.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXgpnPo1y1jw",
        "outputId": "af4362a9-6d6d-4dc3-e845-dbb4ccb6e066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat', SMS_Tokens=['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni', SMS_Tokens=['ok', 'lar', 'joking', 'wif', 'u', 'oni']),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s', SMS_Tokens=['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'questionstd', 'txt', 'ratetcs', 'apply', '08452810075over18s'])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing stop words from SMS_Tokens and storing the result in a new column : SMS_Stop\n",
        "# Updating SMS_Processed with stop words removed, and SMS_Tokens and SMS_Stop columns dropped\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "remover = StopWordsRemover(stopWords=stop_words, inputCol='SMS_Tokens', outputCol='SMS_Stop')\n",
        "df_processed = remover.transform(df_processed)\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.concat_ws(' ', 'SMS_Stop'))\n",
        "columns = ('SMS_Stop', 'SMS_Tokens')\n",
        "df_processed = df_processed.drop(*columns)\n",
        "df_processed.take(5)\n",
        "#df1.join(df2, df1.ID == df2.ID).select(df1['*'], df2['col'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqaWE4tOtm2U",
        "outputId": "7ce60d7e-8604-4fd1-b5c6-6a298fc4f826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go jurong point crazy available bugis n great world la e buffet cine got amore wat'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s'),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say early hor u c already say'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed='nah dont think goes usf lives around though')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmetizing the text data to root word by combining NLTK and PySpark udf functinalities\n",
        "# Updating the SMS_processed column with lemmatized words\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer_udf = f.udf(lambda row: [lemmatizer.lemmatize(x) for x in row if x not in stop_words],\n",
        "                       ArrayType(StringType()))\n",
        "tokenizer = Tokenizer(inputCol='SMS_Processed', outputCol='SMS_Tokens')\n",
        "df_processed = tokenizer.transform(df_processed)\n",
        "df_processed = df_processed.withColumn('SMS_Lemmetize', lemmatizer_udf(f.col('SMS_Tokens')))\n",
        "df_processed = df_processed.withColumn('SMS_Processed', f.concat_ws(' ', 'SMS_Lemmetize'))\n",
        "columns = ('SMS_Lemmetize', 'SMS_Tokens')\n",
        "df_processed = df_processed.drop(*columns)\n",
        "df_processed.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZaWbrmhnQXY",
        "outputId": "a41e2e34-5179-41ce-9037-c7c086cade5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go jurong point crazy available bugis n great world la e buffet cine got amore wat'),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni'),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s'),\n",
              " Row(Flag='ham', SMS='U dun say so early hor... U c already then say...', ID=3, Spam=0.0, SMS_Processed='u dun say early hor u c already say'),\n",
              " Row(Flag='ham', SMS=\"Nah I don't think he goes to usf, he lives around here though\", ID=4, Spam=0.0, SMS_Processed='nah dont think go usf life around though')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Term Frequency-Inverse Document Frequency embedding features on SMS_Processed data\n",
        "\n",
        "# Tokenizing the lemmetized text data and saving results in new column : SMS_Tokens\n",
        "tokenizer = Tokenizer(inputCol='SMS_Processed', outputCol='SMS_Tokens')\n",
        "df_processed = tokenizer.transform(df_processed)\n",
        "\n",
        "# Hashing the tokenized data and saving results in new column : TFFeatures\n",
        "hashingTF = HashingTF(inputCol='SMS_Tokens', outputCol='TFFeatures', numFeatures=400)\n",
        "df_processed = hashingTF.transform(df_processed)\n",
        "\n",
        "# Creating TF-IDF features on hashed data and saving results in new column : IDFfeatures\n",
        "idf = IDF(inputCol='TFFeatures', outputCol='IDFfeatures')\n",
        "idfModel = idf.fit(df_processed)\n",
        "df_processed = idfModel.transform(df_processed)\n",
        "\n",
        "df_processed.take(3)"
      ],
      "metadata": {
        "id": "0n5LNVF_X8__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56399b8e-2e67-4919-e420-7446f81b7e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Flag='ham', SMS='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', ID=0, Spam=0.0, SMS_Processed='go jurong point crazy available bugis n great world la e buffet cine got amore wat', SMS_Tokens=['go', 'jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amore', 'wat'], TFFeatures=SparseVector(400, {6: 1.0, 7: 1.0, 47: 1.0, 55: 1.0, 77: 1.0, 91: 1.0, 165: 1.0, 182: 1.0, 260: 1.0, 278: 1.0, 287: 1.0, 350: 1.0, 362: 1.0, 371: 1.0, 385: 1.0, 390: 1.0}), IDFfeatures=SparseVector(400, {6: 3.7509, 7: 3.0463, 47: 3.7819, 55: 2.883, 77: 2.7971, 91: 3.9532, 165: 3.3896, 182: 4.1262, 260: 3.1707, 278: 3.4499, 287: 4.583, 350: 3.7134, 362: 4.5152, 371: 4.583, 385: 4.8194, 390: 3.6988})),\n",
              " Row(Flag='ham', SMS='Ok lar... Joking wif u oni...', ID=1, Spam=0.0, SMS_Processed='ok lar joking wif u oni', SMS_Tokens=['ok', 'lar', 'joking', 'wif', 'u', 'oni'], TFFeatures=SparseVector(400, {20: 1.0, 76: 1.0, 84: 1.0, 113: 1.0, 278: 1.0, 326: 1.0}), IDFfeatures=SparseVector(400, {20: 3.9439, 76: 3.4613, 84: 2.6991, 113: 4.2693, 278: 3.4499, 326: 1.7791})),\n",
              " Row(Flag='spam', SMS=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", ID=2, Spam=1.0, SMS_Processed='free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s', SMS_Tokens=['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', '87121', 'receive', 'entry', 'questionstd', 'txt', 'ratetcs', 'apply', '08452810075over18s'], TFFeatures=SparseVector(400, {9: 1.0, 30: 1.0, 59: 1.0, 70: 1.0, 128: 1.0, 140: 1.0, 184: 1.0, 233: 1.0, 234: 1.0, 235: 1.0, 266: 1.0, 273: 1.0, 274: 1.0, 279: 1.0, 287: 2.0, 294: 1.0, 308: 1.0, 316: 1.0, 346: 2.0, 369: 1.0, 389: 1.0}), IDFfeatures=SparseVector(400, {9: 3.8987, 30: 2.6346, 59: 4.9372, 70: 3.0615, 128: 3.7585, 140: 4.2822, 184: 4.3776, 233: 4.1152, 234: 4.0617, 235: 4.2316, 266: 3.0093, 273: 2.6676, 274: 4.6371, 279: 3.5956, 287: 9.166, 294: 4.0109, 308: 3.9721, 316: 3.6288, 346: 4.3323, 369: 3.2279, 389: 2.2459}))]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model Development : Random Forest Classifier in PySpark"
      ],
      "metadata": {
        "id": "aDkf_1Z5bwzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting 3 columns for model development. TF-IDF features serve as X variables, and Spam as Y variable\n",
        "df_model = df_processed.select(['ID', 'Spam', 'IDFfeatures'])\n",
        "df_model.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7P5kuSK7TXZ",
        "outputId": "a084229d-a613-42eb-999e-4a818b3b14be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(ID=0, Spam=0.0, IDFfeatures=SparseVector(400, {6: 3.7509, 7: 3.0463, 47: 3.7819, 55: 2.883, 77: 2.7971, 91: 3.9532, 165: 3.3896, 182: 4.1262, 260: 3.1707, 278: 3.4499, 287: 4.583, 350: 3.7134, 362: 4.5152, 371: 4.583, 385: 4.8194, 390: 3.6988})),\n",
              " Row(ID=1, Spam=0.0, IDFfeatures=SparseVector(400, {20: 3.9439, 76: 3.4613, 84: 2.6991, 113: 4.2693, 278: 3.4499, 326: 1.7791})),\n",
              " Row(ID=2, Spam=1.0, IDFfeatures=SparseVector(400, {9: 3.8987, 30: 2.6346, 59: 4.9372, 70: 3.0615, 128: 3.7585, 140: 4.2822, 184: 4.3776, 233: 4.1152, 234: 4.0617, 235: 4.2316, 266: 3.0093, 273: 2.6676, 274: 4.6371, 279: 3.5956, 287: 9.166, 294: 4.0109, 308: 3.9721, 316: 3.6288, 346: 4.3323, 369: 3.2279, 389: 2.2459}))]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting model development data into train and test data\n",
        "\n",
        "df_train, df_test = df_model.randomSplit([0.85, 0.15], seed=21)\n",
        "df_train.count(), df_test.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgh9p6db3Cl5",
        "outputId": "4a462d3d-c2a2-43fd-d130-183fc683f431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4727, 847)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v-xgLSKxDu49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building base Random Forest model on Train data and getting model predicitons Test data\n",
        "rf = RandomForestClassifier(labelCol='Spam', featuresCol='IDFfeatures', numTrees=200, maxDepth=5, seed=21)\n",
        "rf_model = rf.fit(df_train)\n",
        "rf_predictions = rf_model.transform(df_test)\n",
        "rf_predictions.select('ID', 'Spam', 'prediction', 'probability').take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFpxWVL38Gaa",
        "outputId": "5d1768a3-cf19-4803-9898-2f29ebe64419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(ID=1, Spam=0.0, prediction=0.0, probability=DenseVector([0.9251, 0.0749])),\n",
              " Row(ID=7, Spam=0.0, prediction=0.0, probability=DenseVector([0.8256, 0.1744])),\n",
              " Row(ID=10, Spam=0.0, prediction=0.0, probability=DenseVector([0.9222, 0.0778]))]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating base Random Forest model performance on Test data using AUROC and Accuracy metrics\n",
        "\n",
        "rf_evaluator_roc = BinaryClassificationEvaluator(metricName='areaUnderROC', labelCol='Spam')\n",
        "rf_evaluator_acc = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='Spam')\n",
        "auROC = round((rf_evaluator_roc.evaluate(rf_predictions)),2)\n",
        "accuracy = round(((rf_evaluator_acc.evaluate(rf_predictions))*100),2)\n",
        "print('Test auROC = {}'.format(auROC))\n",
        "print('Test Accuracy = {}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t4wyfan-9yk",
        "outputId": "c3688b71-15cb-4731-c4b0-5c6e759ec129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test auROC = 0.96\n",
            "Test Accuracy = 88.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Hyperparameter Tuning in Pyspark"
      ],
      "metadata": {
        "id": "iEcm8Bu4c5wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the hyparameter grid\n",
        "parameter_grid = (ParamGridBuilder()\n",
        "                  .addGrid(rf.maxDepth, [5,6,7])\n",
        "                  .addGrid(rf.numTrees, [150, 200, 250])\n",
        "                  .build())\n",
        "\n",
        "# defining two model evaluation metrics, however the model will be tuned on AUROC values\n",
        "rf_evaluator_roc = BinaryClassificationEvaluator(metricName='areaUnderROC', labelCol='Spam')\n",
        "rf_evaluator_acc = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='Spam')\n",
        "\n",
        "# fitting model on train data and calculating predictions on test data\n",
        "cv = CrossValidator(estimator=rf, evaluator=rf_evaluator_roc,\n",
        "                    estimatorParamMaps=parameter_grid, numFolds=3, parallelism = 4)\n",
        "rf_cv_model = cv.fit(df_train)\n",
        "rf_cv_predictions = rf_cv_model.transform(df_test)\n",
        "rf_predictions.select('ID', 'Spam', 'prediction', 'probability').take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3-HyAhM-i7y",
        "outputId": "d9331984-9eda-4951-fc69-4e1fc51327e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(ID=1, Spam=0.0, prediction=0.0, probability=DenseVector([0.9251, 0.0749])),\n",
              " Row(ID=7, Spam=0.0, prediction=0.0, probability=DenseVector([0.8256, 0.1744])),\n",
              " Row(ID=10, Spam=0.0, prediction=0.0, probability=DenseVector([0.9222, 0.0778]))]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating performance of tuned Random Forest model \n",
        "auROC = round((rf_evaluator_roc.evaluate(rf_cv_predictions)),2)\n",
        "accuracy = round(((rf_evaluator_acc.evaluate(rf_cv_predictions))*100),2)\n",
        "print('Test auROC = {}'.format(auROC))\n",
        "print('Test Accuracy = {}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeDUPiigEfJg",
        "outputId": "a4e50f17-860d-4ed1-ea1b-1547184d6354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test auROC = 0.97\n",
            "Test Accuracy = 89.96%\n"
          ]
        }
      ]
    }
  ]
}